{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mock Draft 2016\n",
    "\n",
    "### Analyzing and modleing from the \"expert\" predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import cross_validation\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from pandas import DataFrame\n",
    "from sklearn import feature_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is compiled in a .csv file containing first round draft predictions from ESPN (Todd McShay and/or Mel Kiper), Bleacher Report, and Walter Football."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, which \"expert\" has been the most accurate over the past 10 years?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"draft_mock_plus_stats.csv\") as f:\n",
    "    next(f)\n",
    "    espn=0\n",
    "    br=0\n",
    "    wf=0\n",
    "    total=0\n",
    "    for line in f:\n",
    "        if line.split(\",\")[6].strip() != \"\":\n",
    "            total+=1\n",
    "            if line.split(\",\")[2].strip() == line.split(\",\")[6].strip():\n",
    "                espn+=1\n",
    "            if line.split(\",\")[3].strip() == line.split(\",\")[6].strip():\n",
    "                br+=1\n",
    "            if line.split(\",\")[4].strip() == line.split(\",\")[6].strip():\n",
    "                wf+=1\n",
    "print \"ESPN:\\t\\t\", float(espn)/float(total)\n",
    "print \"BleacherReport:\\t\", float(br)/float(total)\n",
    "print \"WalterFootball:\\t\", float(wf)/float(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.read_csv(\"draft_mock_plus_stats.csv\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the relevant data and omit teams with no first round draft pick from the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_teams=pd.read_csv(\"draft_mock_plus_stats.csv\")\n",
    "picks=all_teams.dropna(subset=['IsOffense'])\n",
    "print picks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(picks)\n",
    "#print df\n",
    "data_array = df.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exp_preds = data_array[:, 2:5]\n",
    "print exp_preds.shape\n",
    "actual_pick = data_array[:,6]\n",
    "exp_preds = pd.DataFrame(exp_preds, columns=['ESPN', 'BeacherReport', 'WalterFootball'])\n",
    "\n",
    "print exp_preds.shape\n",
    "print actual_pick.shape\n",
    "\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(exp_preds, actual_pick, test_size=0.25, random_state=3)\n",
    "\n",
    "X_train.shape, y_train.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "scores=cross_val_score(logreg, exp_preds, np.array(actual_pick.astype(int)), cv=10, scoring='accuracy')\n",
    "print scores\n",
    "print scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logreg_model = logreg.fit(X_train, y_train.astype(int))\n",
    "print logreg_model.score(X_train, y_train.astype(int))\n",
    "print logreg_model.predict([[0,0,1]])\n",
    "#print logreg_model.predict([[0,1,0]])\n",
    "#print logreg_model.predict([[0,0,1]])\n",
    "#print logreg_model.predict([[0,1,1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier()\n",
    "scores=cross_val_score(rf_model, exp_preds, np.array(actual_pick.astype(int)), cv=10, scoring='accuracy')\n",
    "#rf_model = rf_model.fit(X_train, y_train)\n",
    "print scores\n",
    "print scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svm_model=svm.SVC()\n",
    "scores=cross_val_score(svm_model, exp_preds, np.array(actual_pick.astype(int)), cv=10, scoring='accuracy')\n",
    "print scores\n",
    "print scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_selection.f_classif(exp_preds, np.array(actual_pick.astype(int)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k_range=range(1,51)\n",
    "k_scores1=[]\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores=cross_val_score(knn, exp_preds, np.array(actual_pick.astype(int)), cv=10, scoring='accuracy')\n",
    "    k_scores1.append(scores.mean())\n",
    "print k_scores1\n",
    "avg_kscore = sum(k_scores1)/len(k_scores1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(k_range, k_scores1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Max accuracy at k=13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_selection.f_classif(exp_preds, np.array(actual_pick.astype(int)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now what happens to accuracy when we also consider stats from previous season?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exp_preds = data_array[:, 2:6]\n",
    "actual_pick = data_array[:,6]\n",
    "exp_preds = pd.DataFrame(exp_preds, columns=['ESPN', 'BeacherReport', 'WalterFootball', 'OffensiveBias'])\n",
    "\n",
    "\n",
    "print exp_preds.shape\n",
    "print actual_pick.shape\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(exp_preds, actual_pick, test_size=0.25, random_state=3)\n",
    "\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "scores=cross_val_score(logreg, exp_preds, np.array(actual_pick.astype(int)), cv=10, scoring='accuracy')\n",
    "print scores\n",
    "print scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logreg_model = logreg.fit(X_train, y_train.astype(int))\n",
    "print logreg_model.score(X_train, y_train.astype(int))\n",
    "print logreg_model.predict([[0,1,1,32]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier()\n",
    "scores=cross_val_score(rf_model, exp_preds, np.array(actual_pick.astype(int)), cv=10, scoring='accuracy')\n",
    "print scores\n",
    "print scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svm_model=svm.SVC()\n",
    "scores=cross_val_score(svm_model, exp_preds, np.array(actual_pick.astype(int)), cv=10, scoring='accuracy')\n",
    "print scores\n",
    "print scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k_range=range(1,51)\n",
    "k_scores=[]\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores=cross_val_score(knn, exp_preds, np.array(actual_pick.astype(int)), cv=10, scoring='accuracy')\n",
    "    k_scores.append(scores.mean())\n",
    "print k_scores\n",
    "avg_kscore = sum(k_scores)/len(k_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(k_range, k_scores1, label='Without Team Stats')\n",
    "plt.plot(k_range, k_scores, label='With Team Stats')\n",
    "plt.xticks(fontsize=14)\n",
    "plt.xlabel('Neighbors', fontsize='28')\n",
    "plt.yticks(fontsize=14)\n",
    "plt.ylabel('Accuracy', fontsize='28')\n",
    "legend = plt.legend(loc='center right', prop={'size':16})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_selection.f_classif(exp_preds, np.array(actual_pick.astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
